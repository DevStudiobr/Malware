import requests
from bs4 import BeautifulSoup
import re
import os

# Cores para terminal
class Cores:
    VERDE = "\033[92m"
    VERMELHO = "\033[91m"
    AMARELO = "\033[93m"
    AZUL = "\033[94m"
    RESETAR = "\033[0m"

# Lista de domínios e palavras-chave suspeitas
dominios_suspeitos = ["malware.com", "badsite.org", "suspicious.net"]
palavras_suspeitas = ["tracking", "analytics", "malicious", "adware", "spyware", "phishing"]

def validar_url(url):
    """Valida se a URL está em um formato correto."""
    regex = re.compile(
        r'^(?:http|ftp)s?://' # protocolo
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' # domínio
        r'localhost|' # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|' # IPv4
        r'?[A-F0-9]*:[A-F0-9:]+?)' # IPv6
        r'(?::\d+)?' # porta
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return re.match(regex, url) is not None

def verificar_url(url):
    if not url.startswith("http"):
        url = "http://" + url

    if not validar_url(url):
        print(Cores.VERMELHO + "URL inválida! Por favor, insira uma URL válida." + Cores.RESETAR)
        return

    try:
        resposta = requests.get(url, timeout=10)

        if resposta.status_code == 200:
            soup = BeautifulSoup(resposta.content, 'html.parser')

            # Analisando links, iframes e scripts
            links_suspeitos = [link['href'] for link in soup.find_all('a', href=True) if "http" in link['href'] and any(suspeito in link['href'] for suspeito in dominios_suspeitos + palavras_suspeitas)]
            iframes_suspeitos = [iframe['src'] for iframe in soup.find_all('iframe', src=True) if "http" in iframe['src'] and url not in iframe['src']]
            scripts_suspeitos = [script['src'] for script in soup.find_all('script', src=True) if "http" in script['src'] and any(suspeito in script['src'] for suspeito in palavras_suspeitas + dominios_suspeitos)]

            # Relatório de resultados
            print(Cores.AZUL + "\nResultados da Verificação de URL:" + Cores.RESETAR)
            print(Cores.VERDE + f"Links suspeitos encontrados ({len(links_suspeitos)}):\n" + Cores.RESETAR + "\n".join(links_suspeitos) if links_suspeitos else Cores.VERMELHO + "Nenhum link suspeito encontrado." + Cores.RESETAR)
            print(Cores.VERDE + f"iFrames suspeitos encontrados ({len(iframes_suspeitos)}):\n" + Cores.RESETAR + "\n".join(iframes_suspeitos) if iframes_suspeitos else Cores.VERMELHO + "Nenhum iFrame suspeito encontrado." + Cores.RESETAR)
            print(Cores.VERDE + f"Scripts suspeitos encontrados ({len(scripts_suspeitos)}):\n" + Cores.RESETAR + "\n".join(scripts_suspeitos) if scripts_suspeitos else Cores.VERMELHO + "Nenhum script suspeito encontrado." + Cores.RESETAR)

            # Log de resultados
            log_resultados(url, links_suspeitos, iframes_suspeitos, scripts_suspeitos)

        else:
            print(Cores.VERMELHO + f"Erro: Código de status {resposta.status_code}" + Cores.RESETAR)

    except requests.exceptions.RequestException as e:
        print(Cores.VERMELHO + f"Erro ao verificar a URL: {e}" + Cores.RESETAR)

def log_resultados(url, links, iframes, scripts):
    """Armazena os resultados em um arquivo de log."""
    log_filename = "resultados_log.txt"
    with open(log_filename, "a") as log_file:
        log_file.write(f"URL: {url}\n")
        log_file.write(f"Links suspeitos encontrados ({len(links)}): {', '.join(links) if links else 'Nenhum'}\n")
        log_file.write(f"iFrames suspeitos encontrados ({len(iframes)}): {', '.join(iframes) if iframes else 'Nenhum'}\n")
        log_file.write(f"Scripts suspeitos encontrados ({len(scripts)}): {', '.join(scripts) if scripts else 'Nenhum'}\n")
        log_file.write("-" * 50 + "\n")

# Loop principal
if __name__ == "__main__":
    while True:
        url = input(Cores.AMARELO + "Digite a URL para verificar (ou 'sair' para encerrar): " + Cores.RESETAR)
        if url.lower() == 'sair':
            break
        verificar_url(url)
